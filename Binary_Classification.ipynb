{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yuncs\\anaconda3\\envs\\yolov7\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([-0.5659], grad_fn=<AddBackward0>)\n",
      "tensor([-0.5659], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "x = torch.tensor([1.])\n",
    "print(x)\n",
    "model = nn.Linear(1,1)\n",
    "#print(model.weight)\n",
    "#print(model.bias)\n",
    "print(model(x))\n",
    "y = x @ model.weight + model.bias # perceptron why? entropy\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron, MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1097], grad_fn=<AddBackward0>)\n",
      "tensor([-0.1097], grad_fn=<AddBackward0>)\n",
      "tensor([0.2639], grad_fn=<AddBackward0>)\n",
      "tensor([0.1194], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "fc1 = nn.Linear(1,100)\n",
    "fc2 = nn.Linear(100,1)\n",
    "\n",
    "x = torch.tensor([1.])\n",
    "print(fc2(fc1(x)))\n",
    "y = (x @ fc1.weight.T + fc1.bias) @ fc2.weight.T + fc2.bias\n",
    "print(y)\n",
    "\n",
    "model = nn.Sequential(nn.Linear(1,100), \n",
    "                      nn.Linear(100,1))\n",
    "print(model(x))\n",
    "\n",
    "# create model class\n",
    "class my_model(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.my_layer = nn.Sequential(nn.Linear(1,100), \n",
    "                                      nn.Linear(100,1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.my_layer(x)\n",
    "        return x\n",
    "\n",
    "model = my_model()\n",
    "x = torch.tensor([1.])\n",
    "y = model(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP train using dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yuncs\\anaconda3\\envs\\yolov7\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([331, 6]) torch.Size([83, 6]) torch.Size([331, 1]) torch.Size([83, 1])\n",
      "epoch: 0, train_loss: 11.553, my_loss: 11.552\n",
      "epoch: 1, train_loss: 11.549, my_loss: 11.549\n",
      "epoch: 2, train_loss: 11.541, my_loss: 11.541\n",
      "epoch: 3, train_loss: 11.531, my_loss: 11.531\n",
      "epoch: 4, train_loss: 11.518, my_loss: 11.518\n",
      "epoch: 5, train_loss: 11.502, my_loss: 11.502\n",
      "epoch: 6, train_loss: 11.485, my_loss: 11.485\n",
      "epoch: 7, train_loss: 11.465, my_loss: 11.465\n",
      "epoch: 8, train_loss: 11.443, my_loss: 11.443\n",
      "epoch: 9, train_loss: 11.42, my_loss: 11.42\n",
      "epoch: 10, train_loss: 11.395, my_loss: 11.395\n",
      "epoch: 11, train_loss: 11.369, my_loss: 11.369\n",
      "epoch: 12, train_loss: 11.341, my_loss: 11.341\n",
      "epoch: 13, train_loss: 11.313, my_loss: 11.313\n",
      "epoch: 14, train_loss: 11.284, my_loss: 11.284\n",
      "epoch: 15, train_loss: 11.253, my_loss: 11.253\n",
      "epoch: 16, train_loss: 11.222, my_loss: 11.222\n",
      "epoch: 17, train_loss: 11.191, my_loss: 11.191\n",
      "epoch: 18, train_loss: 11.158, my_loss: 11.158\n",
      "epoch: 19, train_loss: 11.125, my_loss: 11.125\n",
      "epoch: 20, train_loss: 11.092, my_loss: 11.092\n",
      "epoch: 21, train_loss: 11.058, my_loss: 11.058\n",
      "epoch: 22, train_loss: 11.024, my_loss: 11.024\n",
      "epoch: 23, train_loss: 10.989, my_loss: 10.989\n",
      "epoch: 24, train_loss: 10.954, my_loss: 10.954\n",
      "epoch: 25, train_loss: 10.919, my_loss: 10.919\n",
      "epoch: 26, train_loss: 10.883, my_loss: 10.883\n",
      "epoch: 27, train_loss: 10.847, my_loss: 10.847\n",
      "epoch: 28, train_loss: 10.811, my_loss: 10.811\n",
      "epoch: 29, train_loss: 10.775, my_loss: 10.775\n",
      "epoch: 30, train_loss: 10.738, my_loss: 10.738\n",
      "epoch: 31, train_loss: 10.702, my_loss: 10.702\n",
      "epoch: 32, train_loss: 10.665, my_loss: 10.665\n",
      "epoch: 33, train_loss: 10.628, my_loss: 10.628\n",
      "epoch: 34, train_loss: 10.591, my_loss: 10.591\n",
      "epoch: 35, train_loss: 10.554, my_loss: 10.554\n",
      "epoch: 36, train_loss: 10.517, my_loss: 10.517\n",
      "epoch: 37, train_loss: 10.479, my_loss: 10.479\n",
      "epoch: 38, train_loss: 10.442, my_loss: 10.442\n",
      "epoch: 39, train_loss: 10.405, my_loss: 10.405\n",
      "epoch: 40, train_loss: 10.367, my_loss: 10.367\n",
      "epoch: 41, train_loss: 10.329, my_loss: 10.329\n",
      "epoch: 42, train_loss: 10.292, my_loss: 10.292\n",
      "epoch: 43, train_loss: 10.254, my_loss: 10.254\n",
      "epoch: 44, train_loss: 10.216, my_loss: 10.216\n",
      "epoch: 45, train_loss: 10.179, my_loss: 10.179\n",
      "epoch: 46, train_loss: 10.141, my_loss: 10.141\n",
      "epoch: 47, train_loss: 10.103, my_loss: 10.103\n",
      "epoch: 48, train_loss: 10.065, my_loss: 10.065\n",
      "epoch: 49, train_loss: 10.027, my_loss: 10.027\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as func\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.linear_model import LinearRegression # using scikit-learn\n",
    "\n",
    "# 01 loading dataset and convert tensor\n",
    "csv_file = pd.read_csv('data/Real_estate.csv')\n",
    "csv_file.drop('No', inplace=True, axis=1)\n",
    "y = csv_file['Y house price of unit area']\n",
    "x = csv_file.drop('Y house price of unit area', axis=1) \n",
    "#print(x.shape, y.shape)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.2, random_state=3, shuffle=True)\n",
    "#print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "Y_train = torch.tensor(Y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "Y_test = torch.tensor(Y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "\n",
    "\"\"\" # using scikit-learn\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "print(pd.DataFrame({'Y_test':Y_test, 'Y_predict':y_predict}).head())\n",
    "\"\"\"\n",
    "\n",
    "# 02 create model class\n",
    "class my_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.my_layer = nn.Sequential(nn.Linear(6, 30),\n",
    "                                      nn.Sigmoid(),\n",
    "                                      nn.Linear(30, 100),\n",
    "                                      nn.Sigmoid(),\n",
    "                                      nn.Sequential(*[i for _ in range(100) for i in [nn.Linear(100,100), nn.Sigmoid()]]),\n",
    "                                      nn.Linear(100,1),\n",
    "                                      nn.Sigmoid())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.my_layer(x)\n",
    "        return x\n",
    "\n",
    "model = my_model()\n",
    "\n",
    "# 03 train created model\n",
    "epoch = 50 # how many train count?\n",
    "LR = 1e-7 # learning rate -> how many update weight?\n",
    "optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n",
    "\n",
    "model.train() # model train mode\n",
    "for ep in range(epoch):\n",
    "    y_h = model(X_train) # forward network\n",
    "    loss_func = func.binary_cross_entropy(y_h, Y_train) # loss function\n",
    "    loss_func_tmp = -(torch.sum(torch.log(y_h**Y_train * (1-y_h)**(1-Y_train)))/331) # loss function\n",
    "    optimizer.zero_grad() # prevent gradient accumulate\n",
    "    loss_func.backward() # backward network (backpropagation)\n",
    "    optimizer.step() # weight update (backpropagation)\n",
    "    # train loss print\n",
    "    print(f\"epoch: {ep}, train_loss: {round(loss_func.item(), 3)}, my_loss: {round(loss_func_tmp.item(), 3)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.])\n",
      "tensor([2.])\n",
      "tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "# prevent gradient accumulate\n",
    "x = torch.tensor([1.], requires_grad=True)\n",
    "for _ in range(3):\n",
    "    loss = x**2 # 식\n",
    "    loss.backward() # 미분 +=\n",
    "    print(x.grad) # 미분결과\n",
    "    x.grad = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
